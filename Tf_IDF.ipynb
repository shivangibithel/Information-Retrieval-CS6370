{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tf-IDF final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pegdxlyXedwx"
      },
      "source": [
        "\r\n",
        "#Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9IumRrab1VI"
      },
      "source": [
        "import nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "def remPunctuations(text):\n",
        "    # table is a translation table for removing the punctuation marks from the words\n",
        "    table = str.maketrans({key: None for key in string.punctuation})\n",
        "    translated = text.translate(table)\n",
        "    return translated\n",
        "def tokenize(text):\n",
        "    return word_tokenize(text)\n",
        "def remStop(tokens):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered = [t for t in tokens if not t in stop_words]\n",
        "    return filtered\n",
        "def lemmatize(tokens):\n",
        "    lz = WordNetLemmatizer()\n",
        "    lemmatized = [lz.lemmatize(t) for t in tokens]\n",
        "    return list(set(lemmatized))\n",
        "def preprocessing(text):\n",
        "  # table is a translation table for removing the punctuation marks from the words\n",
        "    table = str.maketrans({key: None for key in string.punctuation})\n",
        "    translated = text.translate(table)\n",
        "    tokens =word_tokenize(translated)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered = [t for t in tokens if not t in stop_words]\n",
        "    tokens =filtered\n",
        "    lz = WordNetLemmatizer()\n",
        "    lemmatized = [lz.lemmatize(t) for t in tokens]\n",
        "    return list(set(lemmatized))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2MHEGrXS0OX"
      },
      "source": [
        "Mounting to google drive and authorizing to use the files saved in my dirve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXmCNU3IMsFS"
      },
      "source": [
        "import os\n",
        "cwd = os.getcwd()\n",
        "files = os.listdir(cwd) \n",
        "files\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My\\ Drive/IR\\ Project\\ Data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_z54_yJeWvI"
      },
      "source": [
        "# Creating TF-IDF score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysR7qHwATLej"
      },
      "source": [
        "Creating a dictionary from the corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw7f4PzHe1hM"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My\\ Drive/IR\\ group2/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n2J4gmlei88"
      },
      "source": [
        "import pickle\n",
        "with open('datalist.txt', \"rb\") as fp:\n",
        "   dataset=pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGAy6TJNfOLi"
      },
      "source": [
        "#word_tokenize\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "Doc_tokenized=[]\n",
        "for i in range(2914):\n",
        "  Doc_tokenized.append(word_tokenize(dataset[i]))\n",
        "print(Doc_tokenized[0])\n",
        "print(len(Doc_tokenized[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjSYr-YWblst"
      },
      "source": [
        "from gensim import corpora\n",
        "\n",
        "dictionary = corpora.Dictionary(Doc_tokenized)\n",
        "print(dictionary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-GJZVTQU5Hx"
      },
      "source": [
        "import pprint\n",
        "pprint.pprint(dictionary.token2id)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBLdNq1ZVz0f"
      },
      "source": [
        "bow_corpus = [dictionary.doc2bow(text) for text in Doc_tokenized]\n",
        "#pprint.pprint(bow_corpus)\n",
        "#bow_corpus from orignal data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOAblsolgD0F"
      },
      "source": [
        "Based on complete corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJQaTz_BXqW-"
      },
      "source": [
        "# for doc in bow_corpus:\n",
        "#    print([[dictionary[id], freq] for id, freq in doc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rNrlzN63CYd"
      },
      "source": [
        "dictionary.save('mydict.dict')\n",
        "corpora.MmCorpus.serialize('bow_corpus.mm', bow_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_ieAw4kZU1M"
      },
      "source": [
        "from gensim import models\n",
        "\n",
        "# train the model\n",
        "tfidf = models.TfidfModel(corpus=bow_corpus,id2word=dictionary,dictionary=dictionary,normalize=True,smartirs='ntc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6aK7v4Vxnpi"
      },
      "source": [
        "vector=[]\r\n",
        "for i in range(2914):\r\n",
        "  v = tfidf[bow_corpus[i]]\r\n",
        "  vector.append(v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD8pc5Mawtax"
      },
      "source": [
        "# Cosine similarity array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66YpZ3CQ46ll"
      },
      "source": [
        "**This is the representations of words and their TF-IDF weights**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKgTXJlfukb3"
      },
      "source": [
        "import pickle\r\n",
        "with open('querylist.txt', \"rb\") as fp:\r\n",
        "    qrs=pickle.load(fp)\r\n",
        "for i in range(50):\r\n",
        " qrs[i]=qrs[i].split(\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK_pwm8YZZyB"
      },
      "source": [
        "from gensim import similarities\n",
        "\n",
        "index = similarities.SparseMatrixSimilarity(tfidf[bow_corpus], num_features=len(dictionary))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgen1ktIkzVL"
      },
      "source": [
        "query_bow = dictionary.doc2bow(qrs[0])\n",
        "sims = index[tfidf[query_bow]]\n",
        "# print(list(enumerate(sims)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj6gIJRJ8HY2"
      },
      "source": [
        "import numpy\r\n",
        "array=[]\r\n",
        "for i in range(50):\r\n",
        "  query_bow = dictionary.doc2bow(qrs[i])\r\n",
        "  sims = index[tfidf[query_bow]]\r\n",
        "  array.append(list(enumerate(sims)))\r\n",
        "# len(array[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5mXujat80Me"
      },
      "source": [
        "import pickle\r\n",
        "with open('cosinesimtfidf.pkl', \"wb\") as fp:\r\n",
        "    pickle.dump(array,fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQR1l_YPfrbs"
      },
      "source": [
        "Similarity index for query 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fID3vf0Kf-u7"
      },
      "source": [
        "count=0\n",
        "for document_number, score in sorted(enumerate(sims), key=lambda x: x[1], reverse=True):\n",
        "    print(document_number, score)\n",
        "    count=count+1\n",
        "    if(document_number==22):\n",
        "      print(count)\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOg7Pg6Y0lLm"
      },
      "source": [
        "import pickle\r\n",
        "with open('sbert_cossim.pkl', \"rb\") as fp:\r\n",
        "    x=pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQrlUDDu1Z2m"
      },
      "source": [
        "for i in range(50):\r\n",
        "  x[i].sort(key=lambda x:x[1],reverse=True)\r\n",
        "x[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuKSDZ7X3lXf"
      },
      "source": [
        "#cosine sim array \r\n",
        "array4=numpy.ndarray(shape=(50,2914))\r\n",
        "for i in range(50):\r\n",
        "  for j in range(2914):\r\n",
        "    array4[i][j]=x[i][j][1]\r\n",
        "array4.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGnLMSPLjPoC"
      },
      "source": [
        "# creating Hashtable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bft0p-id-oCo"
      },
      "source": [
        "list1=[['AILA_Q1', 'C14'], ['AILA_Q1', 'C9'], ['AILA_Q2', 'C27'], ['AILA_Q2', 'C22'], ['AILA_Q3', 'C1'], ['AILA_Q4', 'C182'], ['AILA_Q5', 'C54'], ['AILA_Q5', 'C36'], ['AILA_Q5', 'C155'], ['AILA_Q5', 'C144'], ['AILA_Q5', 'C121'], ['AILA_Q6', 'C152'], ['AILA_Q6', 'C26'], ['AILA_Q6', 'C19'], ['AILA_Q6', 'C99'], ['AILA_Q7', 'C130'], ['AILA_Q8', 'C32'], ['AILA_Q8', 'C125'], ['AILA_Q8', 'C60'], ['AILA_Q9', 'C42'], ['AILA_Q9', 'C90'], ['AILA_Q10', 'C185'], ['AILA_Q10', 'C180'], ['AILA_Q10', 'C86'], ['AILA_Q11', 'C131'], ['AILA_Q11', 'C132'], ['AILA_Q12', 'C8'], ['AILA_Q13', 'C102'], ['AILA_Q13', 'C120'], ['AILA_Q13', 'C40'], ['AILA_Q14', 'C46'], ['AILA_Q15', 'C185'], ['AILA_Q16', 'C166'], ['AILA_Q16', 'C50'], ['AILA_Q17', 'C67'], ['AILA_Q17', 'C23'], ['AILA_Q17', 'C145'], ['AILA_Q18', 'C188'], ['AILA_Q19', 'C63'], ['AILA_Q19', 'C89'], ['AILA_Q19', 'C77'], ['AILA_Q19', 'C142'], ['AILA_Q20', 'C134'], ['AILA_Q20', 'C168'], ['AILA_Q21', 'C48'], ['AILA_Q21', 'C28'], ['AILA_Q21', 'C114'], ['AILA_Q21', 'C113'], ['AILA_Q22', 'C11'], ['AILA_Q22', 'C118'], ['AILA_Q23', 'C88'], ['AILA_Q23', 'C10'], ['AILA_Q24', 'C171'], ['AILA_Q25', 'C29'], ['AILA_Q25', 'C15'], ['AILA_Q25', 'C41'], ['AILA_Q25', 'C105'], ['AILA_Q25', 'C17'], ['AILA_Q25', 'C84'], ['AILA_Q26', 'C116'], ['AILA_Q26', 'C115'], ['AILA_Q26', 'C44'], ['AILA_Q26', 'C183'], ['AILA_Q26', 'C179'], ['AILA_Q26', 'C108'], ['AILA_Q26', 'C133'], ['AILA_Q26', 'C87'], ['AILA_Q27', 'C91'], ['AILA_Q27', 'C73'], ['AILA_Q27', 'C136'], ['AILA_Q27', 'C175'], ['AILA_Q27', 'C161'], ['AILA_Q28', 'C71'], ['AILA_Q28', 'C178'], ['AILA_Q29', 'C66'], ['AILA_Q29', 'C6'], ['AILA_Q29', 'C127'], ['AILA_Q29', 'C159'], ['AILA_Q29', 'C173'], ['AILA_Q29', 'C24'], ['AILA_Q29', 'C63'], ['AILA_Q29', 'C176'], ['AILA_Q29', 'C156'], ['AILA_Q29', 'C62'], ['AILA_Q29', 'C153'], ['AILA_Q29', 'C74'], ['AILA_Q29', 'C163'], ['AILA_Q29', 'C124'], ['AILA_Q29', 'C169'], ['AILA_Q29', 'C68'], ['AILA_Q29', 'C138'], ['AILA_Q29', 'C100'], ['AILA_Q29', 'C34'], ['AILA_Q29', 'C140'], ['AILA_Q29', 'C4'], ['AILA_Q29', 'C39'], ['AILA_Q30', 'C148'], ['AILA_Q30', 'C80'], ['AILA_Q30', 'C137'], ['AILA_Q30', 'C97'], ['AILA_Q30', 'C123'], ['AILA_Q30', 'C107'], ['AILA_Q30', 'C167'], ['AILA_Q30', 'C83'], ['AILA_Q30', 'C154'], ['AILA_Q30', 'C56'], ['AILA_Q31', 'C93'], ['AILA_Q31', 'C65'], ['AILA_Q32', 'C122'], ['AILA_Q32', 'C164'], ['AILA_Q32', 'C94'], ['AILA_Q33', 'C186'], ['AILA_Q34', 'C72'], ['AILA_Q34', 'C49'], ['AILA_Q34', 'C143'], ['AILA_Q34', 'C69'], ['AILA_Q34', 'C85'], ['AILA_Q34', 'C25'], ['AILA_Q34', 'C126'], ['AILA_Q34', 'C181'], ['AILA_Q34', 'C165'], ['AILA_Q34', 'C33'], ['AILA_Q34', 'C129'], ['AILA_Q34', 'C3'], ['AILA_Q34', 'C13'], ['AILA_Q35', 'C31'], ['AILA_Q35', 'C184'], ['AILA_Q36', 'C57'], ['AILA_Q36', 'C112'], ['AILA_Q36', 'C172'], ['AILA_Q36', 'C160'], ['AILA_Q36', 'C37'], ['AILA_Q36', 'C55'], ['AILA_Q37', 'C18'], ['AILA_Q37', 'C71'], ['AILA_Q37', 'C178'], ['AILA_Q38', 'C149'], ['AILA_Q38', 'C177'], ['AILA_Q38', 'C101'], ['AILA_Q38', 'C110'], ['AILA_Q38', 'C70'], ['AILA_Q39', 'C95'], ['AILA_Q39', 'C16'], ['AILA_Q39', 'C53'], ['AILA_Q39', 'C128'], ['AILA_Q39', 'C169'], ['AILA_Q39', 'C20'], ['AILA_Q39', 'C104'], ['AILA_Q39', 'C146'], ['AILA_Q39', 'C43'], ['AILA_Q39', 'C187'], ['AILA_Q39', 'C119'], ['AILA_Q39', 'C12'], ['AILA_Q40', 'C135'], ['AILA_Q40', 'C111'], ['AILA_Q41', 'C98'], ['AILA_Q41', 'C96'], ['AILA_Q41', 'C35'], ['AILA_Q41', 'C52'], ['AILA_Q41', 'C94'], ['AILA_Q42', 'C103'], ['AILA_Q42', 'C81'], ['AILA_Q42', 'C150'], ['AILA_Q42', 'C2'], ['AILA_Q43', 'C157'], ['AILA_Q43', 'C151'], ['AILA_Q43', 'C158'], ['AILA_Q44', 'C7'], ['AILA_Q44', 'C117'], ['AILA_Q44', 'C109'], ['AILA_Q44', 'C64'], ['AILA_Q44', 'C45'], ['AILA_Q44', 'C61'], ['AILA_Q45', 'C78'], ['AILA_Q45', 'C58'], ['AILA_Q46', 'C5'], ['AILA_Q46', 'C170'], ['AILA_Q46', 'C59'], ['AILA_Q46', 'C75'], ['AILA_Q46', 'C47'], ['AILA_Q46', 'C106'], ['AILA_Q46', 'C79'], ['AILA_Q46', 'C147'], ['AILA_Q46', 'C139'], ['AILA_Q47', 'C171'], ['AILA_Q48', 'C82'], ['AILA_Q48', 'C162'], ['AILA_Q48', 'C141'], ['AILA_Q48', 'C21'], ['AILA_Q49', 'C174'], ['AILA_Q49', 'C38'], ['AILA_Q49', 'C76'], ['AILA_Q49', 'C92'], ['AILA_Q50', 'C27'], ['AILA_Q50', 'C22']] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzbgGWdY-qv_"
      },
      "source": [
        "HashTable = [[] for _ in range(50)] \r\n",
        "def Hashing(keyvalue): \r\n",
        "    return keyvalue % len(HashTable) \r\n",
        "\r\n",
        "def insert(Hashtable, keyvalue, value): \r\n",
        "      \r\n",
        "    hash_key = Hashing(keyvalue) \r\n",
        "    Hashtable[hash_key].append(value)\r\n",
        "\r\n",
        "def display_hash(hashTable): \r\n",
        "      \r\n",
        "    for i in range(len(hashTable)): \r\n",
        "        print(i, end = \" \") \r\n",
        "          \r\n",
        "        for j in hashTable[i]: \r\n",
        "            print(\"-->\", end = \" \") \r\n",
        "            print(j, end = \" \") \r\n",
        "              \r\n",
        "        print()\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtnL7piQ-uhf",
        "outputId": "ec6a4944-c913-4f78-8060-cb545d7d64a8"
      },
      "source": [
        "count=0\r\n",
        "for i in list1:\r\n",
        "  for j in range(1):\r\n",
        "    list0=list(i[0])\r\n",
        "    number=int(''.join(list0[6:]))\r\n",
        "    list2=list(i[1])\r\n",
        "    docnumber=int(''.join(list2[1:]))\r\n",
        "    insert(HashTable, number-1, docnumber-1) \r\n",
        "    count=count+1\r\n",
        "count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "195"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBXBe43k_1dB"
      },
      "source": [
        "# Results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGeneJjf_2BS"
      },
      "source": [
        "Qlist=[]\r\n",
        "topn=[]\r\n",
        "rel_list1=[]\r\n",
        "for i in range(50):\r\n",
        "  dict1={}\r\n",
        "  for j in range(2914):\r\n",
        "        dict1[j]=x.T[i][j]\r\n",
        "  sorted_x={}\r\n",
        "  topq=[]\r\n",
        "  sorted_x = sorted(dict1.items(), key=lambda kv: kv[1],reverse=True)\r\n",
        "  for k in range(10):\r\n",
        "    topq.append(sorted_x[k])\r\n",
        "  topn.append(topq)\r\n",
        "  #print(sorted_x)\r\n",
        "  print(\"For Query\"+ str(i+1))\r\n",
        "  rel_doc=[]\r\n",
        "  for k in range(2914):    \r\n",
        "    for z in HashTable[i]:\r\n",
        "      if(sorted_x[k][0]==z):\r\n",
        "        print(\"Rank of document\"+str(z+1))\r\n",
        "        print(k+1)\r\n",
        "        rel_list1.append(k+1)\r\n",
        "        rel_doc.append(z)\r\n",
        "  Qlist.append(rel_doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPCObmFTvggB"
      },
      "source": [
        "# Precision@10, Recall@10, Fscore and MRR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhQ3MBR_vggN"
      },
      "source": [
        "counter=[0,0,0,0,0,0,0,0,0]\r\n",
        "for i in rel_list1:\r\n",
        "  if(i>0 and i<=100):\r\n",
        "    #print(i)\r\n",
        "    counter[0]=counter[0]+1\r\n",
        "  elif(i>100 and i<=200):\r\n",
        "    counter[1]=counter[1]+1\r\n",
        "  elif(i>200 and i<=300):\r\n",
        "    counter[2]=counter[2]+1\r\n",
        "  elif(i>300 and i<=400):\r\n",
        "    counter[3]=counter[3]+1\r\n",
        "  elif(i>400 and i<=500):\r\n",
        "    counter[4]=counter[4]+1\r\n",
        "  elif(i>500 and i<=1000):\r\n",
        "    counter[5]=counter[5]+1\r\n",
        "  elif(i>1000 and i<=1500):\r\n",
        "    counter[6]=counter[6]+1\r\n",
        "  elif(i>1500 and i<=2000):\r\n",
        "    counter[7]=counter[7]+1\r\n",
        "  else:\r\n",
        "    counter[8]=counter[8]+1\r\n",
        "counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doapL0LpvggR"
      },
      "source": [
        "count of number of documents matching with the ground truth on top 10 for every query\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2EEHGPbvggQ"
      },
      "source": [
        "precision=[]\r\n",
        "for i in range(50):\r\n",
        "  counting=0\r\n",
        "  for j in range(10):\r\n",
        "    for k in range(len(Qlist[i])):\r\n",
        "      #print(topn[i][j][0],Qlist[i][k])\r\n",
        "      if(int(topn[i][j][0])==int(Qlist[i][k])):\r\n",
        "        print(counting)\r\n",
        "        counting=counting+1\r\n",
        "  precision.append(counting)\r\n",
        "print(precision)\r\n",
        "bins=[]\r\n",
        "for i in range(50):\r\n",
        "  bins.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcE42mEOvggT"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "fig = plt.figure()\r\n",
        "ax = fig.add_axes([0,0,1,1])\r\n",
        "a = np.array(precision)\r\n",
        "ax.bar(bins,a)\r\n",
        "plt.xlabel(\"Query Number\")\r\n",
        "plt.ylabel(\"Precision\")\r\n",
        "plt.title(\"Precision @10\")\r\n",
        "#plt.savefig('figure1.png')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvwIOdB3vggT"
      },
      "source": [
        "Recall"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB4NCpKmvggT"
      },
      "source": [
        "recall=[0]*50\r\n",
        "for i in range(50):\r\n",
        "  recall[i]=precision[i]/len(Qlist[i])\r\n",
        "print(recall)\r\n",
        "ans=sum(recall)/50\r\n",
        "ans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7n933n2vggU"
      },
      "source": [
        "Precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXO349NDvggU"
      },
      "source": [
        "for i in range(50): \r\n",
        "  precision[i]=precision[i]/10\r\n",
        "print(precision)\r\n",
        "ans=sum(precision)/50\r\n",
        "ans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SNVP51ZvggV"
      },
      "source": [
        "fScore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHGU5irVvggV"
      },
      "source": [
        "f=0.0\r\n",
        "def fscore(p,r):\r\n",
        "  f=(2*p*r)/(p+r)\r\n",
        "  return f\r\n",
        "Fscore=[0.0]*50\r\n",
        "for i in range(50):\r\n",
        "  if recall[i]!=0.0:\r\n",
        "    Fscore[i]=fscore(precision[i],recall[i])\r\n",
        "print(Fscore)\r\n",
        "ans=sum(Fscore)/50\r\n",
        "ans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2fG4H-qvggW"
      },
      "source": [
        "Mean Average Precision @N"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWo3i2mwvggW"
      },
      "source": [
        "map=(1/50)*(sum(precision))\r\n",
        "print(map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a-H--zfrt8J"
      },
      "source": [
        "rel_list=[]\r\n",
        "c=0\r\n",
        "for i in range(50):\r\n",
        "  dict1={}\r\n",
        "  c=0\r\n",
        "  for j in range(2914):\r\n",
        "        dict1[j]=x.T[i][j]\r\n",
        "  sorted_x={}\r\n",
        "  sorted_x = sorted(dict1.items(), key=lambda kv: kv[1],reverse=True)\r\n",
        "  print(\"For Query\"+ str(i+1))\r\n",
        "  for k in range(2914):\r\n",
        "       \r\n",
        "    for z in HashTable[i]:\r\n",
        "      if(sorted_x[k][0]==z):\r\n",
        "        print(\"Rank of document\"+str(z+1))\r\n",
        "        print(k+1)\r\n",
        "        if(c==0):\r\n",
        "          rel_list.append(k+1)\r\n",
        "          c=c+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1exQh5uqX0s",
        "outputId": "1ef68fc3-072a-4620-b512-a5c24945030c"
      },
      "source": [
        "MRR=[0]*50\r\n",
        "for i in range(50):\r\n",
        "  MRR[i]=1/rel_list[i]\r\n",
        "\r\n",
        "mrr=(1/50)*sum(MRR)\r\n",
        "mrr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0675678010049712"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    }
  ]
}