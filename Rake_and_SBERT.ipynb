{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rake and SBERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYs05Ff5TsUO"
      },
      "source": [
        "# RAKE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfhmibCOlou2"
      },
      "source": [
        "Below is the implementation of RAKE Algorithm which extracts keywords from documents and remove stopwords also.\n",
        "\n",
        "https://www.researchgate.net/publication/227988510_Automatic_Keyword_Extraction_from_Individual_Documents\n",
        "\n",
        "Above is the link to its paper\n",
        "\n",
        "Reason to implement this\n",
        "1. It reduces unnecessary tokens from the text which adds no meaning to text\n",
        "2. Reduces the length of text which is beneficial for BERT now\n",
        "3. Similar to implementation in IR bert paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPddcKWOL-gu"
      },
      "source": [
        "pip install rake-nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBfBUOgoROTt"
      },
      "source": [
        "import nltk\n",
        "import os\n",
        "import string\n",
        "import numpy as np\n",
        "import copy\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import math\n",
        "from rake_nltk import Rake,Metric\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfe5GtZkOyjN",
        "outputId": "30293767-aeba-40d9-c665-4ddbe4e71d50"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/My\\ Drive/IR\\ group2/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/.shortcut-targets-by-id/1RUkqjxZuKOpUEkLIkLfd5Y5fv5UlC-q5/IR group2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR6ncAc4Oapd"
      },
      "source": [
        "import pickle\n",
        "with open('final_data.pkl', 'rb') as fp:\n",
        "  doc = pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtgn9IBQeKkc"
      },
      "source": [
        "import pickle\n",
        "with open('final_query.pkl', 'rb') as fp:\n",
        "  query = pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QoL6O14QpGK"
      },
      "source": [
        "def extract_key(text, r):\n",
        "\t\n",
        "\tr.extract_keywords_from_text(text) \n",
        "\ta = r.get_ranked_phrases()\n",
        "\tt = \"\"\n",
        "\tfor phrase in a:\n",
        "\t\tt = t + ' ' + phrase\n",
        "\treturn t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7IVJPvGefiW"
      },
      "source": [
        "def extract_key(text, w, r):\n",
        "\t\n",
        "\tr.extract_keywords_from_text(text) \n",
        "\ta = r.get_ranked_phrases()\n",
        "\tt = \"\"\n",
        "\tcut = min(w, len(a))\n",
        "\tcount = 0\n",
        "\tfor phrase in a:\n",
        "\t\tif count >= cut:\n",
        "\t\t\tbreak\n",
        "\t\tt = t + ' ' + phrase\n",
        "\t\tcount += 1\n",
        "\treturn t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0-T0SklQd_7"
      },
      "source": [
        "query_corpus = []\n",
        "r = Rake()\n",
        "for i in range(50): \n",
        "  key_text = extract_key(query[i] ,200, r)\n",
        "  query_corpus.append(key_text)\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYYRUNqDenun"
      },
      "source": [
        "text_corpus = []\n",
        "r = Rake()\n",
        "for i in range(2914): \n",
        "  key_text = extract_key(doc[i] ,200, r)\n",
        "  text_corpus.append(key_text)\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-efywKgcblff"
      },
      "source": [
        "import pickle\r\n",
        "with open('rake_text_corpus.pkl', 'wb') as fp:\r\n",
        "  pickle.dump(text_corpus,fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zspAluJSRdbq"
      },
      "source": [
        "# SBERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiA9pzQFzsgn"
      },
      "source": [
        "Implementing SBERT with the help of predtrained embeddings from document text and query text and now computing the similarity score "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlAsdCoIzqdC"
      },
      "source": [
        "pip install -U sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnVS_QWkxZa9"
      },
      "source": [
        "import pickle\n",
        "with open('passage_embedding_corpus.pkl', 'rb') as fp:\n",
        "  passage_embedding_corpus= pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6cRT_JZye22"
      },
      "source": [
        "import pickle\n",
        "with open('q_emb.pkl', 'rb') as fp:\n",
        "  query= pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEbMm2LxzBaK"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer('distilroberta-base-msmarco-v2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT68Q_akfiLm"
      },
      "source": [
        "query=[]\n",
        "for i in range(len(query_corpus)):\n",
        "  query_embedding = model.encode(query_corpus[i])\n",
        "  query.append(query_embedding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grta6vBFyLE3"
      },
      "source": [
        "similarityarray=np.zeros(shape=(2914,50))\n",
        "similaritydoc=0\n",
        "for k in range(len(query)):\n",
        "  for i in range(len(passage_embedding_corpus)):\n",
        "    for j in range(len(passage_embedding_corpus[i])):\n",
        "      similarity=util.pytorch_cos_sim(query[k], passage_embedding_corpus[i][j])\n",
        "      similaritydoc=similaritydoc+similarity\n",
        "    similaritydoc=similaritydoc/len(passage_embedding_corpus[i])\n",
        "    similarityarray[i][k]=np.array(similaritydoc)\n",
        "    similaritydoc=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DZ65dE90NGu",
        "outputId": "33dea29f-1f62-4cf1-eab7-c3f8c3500b36"
      },
      "source": [
        "print(similarityarray)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.32289436 0.51817822 0.39361042 ... 0.49360007 0.51800758 0.51900643]\n",
            " [0.32116768 0.42965642 0.3708612  ... 0.47301197 0.43151057 0.41884822]\n",
            " [0.38772932 0.49233943 0.41018295 ... 0.52661622 0.495877   0.56453204]\n",
            " ...\n",
            " [0.26464292 0.23892173 0.23499994 ... 0.33462954 0.24709587 0.24972513]\n",
            " [0.41093251 0.43496338 0.3963114  ... 0.43778819 0.44921988 0.51846546]\n",
            " [0.27381629 0.43672079 0.38361862 ... 0.41312018 0.45438763 0.39208347]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBF-a4eS1QCA"
      },
      "source": [
        "import pickle\n",
        "with open('sbert_cossim_rakequery.pkl', 'wb') as fp:\n",
        "  pickle.dump(similarityarray,fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArnyqdS8QnS6"
      },
      "source": [
        "similarityarray=np.zeros(shape=(2914,50))\n",
        "similaritydoc=0\n",
        "for k in range(len(query)):\n",
        "  for i in range(len(passage_embedding_corpus)):\n",
        "    for j in range(len(passage_embedding_corpus[i])):\n",
        "      similarity=util.pytorch_cos_sim(query[k], passage_embedding_corpus[i][j])\n",
        "      similaritydoc=similaritydoc+similarity\n",
        "    similaritydoc=similaritydoc/len(passage_embedding_corpus[i])\n",
        "    similarityarray[i][k]=np.array(similaritydoc)\n",
        "    similaritydoc=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9Awfit1Q0B6",
        "outputId": "e635dd3a-6fa1-4576-94fa-d38fc1c591df"
      },
      "source": [
        "print(similarityarray)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.32289442 0.51817811 0.39361039 ... 0.49359995 0.5180074  0.51900643]\n",
            " [0.32116771 0.42965639 0.3708612  ... 0.47301185 0.43151054 0.41884819]\n",
            " [0.38772935 0.49233934 0.41018298 ... 0.52661616 0.49587691 0.56453204]\n",
            " ...\n",
            " [0.26464292 0.23892169 0.23499998 ... 0.33462942 0.24709576 0.24972507]\n",
            " [0.41093263 0.43496329 0.39631143 ... 0.43778816 0.4492197  0.51846546]\n",
            " [0.27381632 0.43672076 0.38361856 ... 0.41312015 0.45438758 0.39208353]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}